{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jP5uwXtZay_",
        "outputId": "3d0194de-4e82-41d9-e70e-315e686a4489"
      },
      "outputs": [],
      "source": [
        "# #run\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXRPF7T0b-QZ",
        "outputId": "821fc7ca-79e6-4cf6-e81d-37fd685b71f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spafe in ./venv/lib/python3.8/site-packages (0.3.2)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.8/site-packages (2.0.3)\n",
            "Requirement already satisfied: tensorflow in ./venv/lib/python3.8/site-packages (2.13.1)\n",
            "Requirement already satisfied: seaborn in ./venv/lib/python3.8/site-packages (0.13.0)\n",
            "Requirement already satisfied: opencv-python in ./venv/lib/python3.8/site-packages (4.8.1.78)\n",
            "Collecting tqdm\n",
            "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m562.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in ./venv/lib/python3.8/site-packages (from spafe) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.7.3 in ./venv/lib/python3.8/site-packages (from spafe) (1.10.1)\n",
            "Requirement already satisfied: typing-extensions in ./venv/lib/python3.8/site-packages (from spafe) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.8/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.8/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in ./venv/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./venv/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in ./venv/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in ./venv/lib/python3.8/site-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./venv/lib/python3.8/site-packages (from tensorflow) (4.24.3)\n",
            "Requirement already satisfied: setuptools in ./venv/lib/python3.8/site-packages (from tensorflow) (56.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in ./venv/lib/python3.8/site-packages (from seaborn) (3.7.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (6.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in ./venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.23.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.3->seaborn) (3.17.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
            "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.66.1\n"
          ]
        }
      ],
      "source": [
        "#run\n",
        "!pip install -U spafe pandas tensorflow seaborn opencv-python tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "s2K5aSHYb-Sm"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import defaultdict\n",
        "from spafe.utils import vis\n",
        "from spafe.features.lfcc import lfcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-xNIFhPtb-U5"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QgbvNKYAb-YM"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import ResNet50,ResNet101\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LXsQV7ivcIcc"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask zero out padding tokens.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  return tf.matmul(attention_weights, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7WB2_09_e-qt"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "# This allows to the transformer to know where there is real data and where it is padded\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PjEQIR8TcIe3"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8hF4xYdLcSQA"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "j7ewC3iBcSSo"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "def encoder_layer(units, d_model, num_heads, dropout,name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "  print(padding_mask)\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_8IFloblcSWJ"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "def encoder(time_steps,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            projection,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  if projection=='linear':\n",
        "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
        "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
        "    print('linear')\n",
        "\n",
        "  else:\n",
        "    projection=tf.identity(inputs)\n",
        "    print('none')\n",
        "\n",
        "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  projection = PositionalEncoding(time_steps, d_model)(projection)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NXgJh2PpcIiK"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "def transformer(time_steps,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                output_size,\n",
        "                projection,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(tf.dtypes.cast(\n",
        "\n",
        "      #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
        "      # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked\n",
        "      tf.math.reduce_sum(\n",
        "      inputs,\n",
        "      axis=2,\n",
        "      keepdims=False,\n",
        "      name=None\n",
        "  ), tf.int32))\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      time_steps=time_steps,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      projection=projection,\n",
        "      name='encoder'\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  #We reshape for feeding our FC in the next step\n",
        "  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
        "\n",
        "  #We predict our class\n",
        "  outputs = tf.keras.layers.Dense(units=output_size,use_bias=True, name=\"outputs\")(outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9H-kkyuLcbPZ"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "# num_batch_size = 32\n",
        "# num_epochs = 500\n",
        "# N_SPLIT = 10\n",
        "# num_labels=5\n",
        "# num_classes=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Iw3KzecbRt",
        "outputId": "0ffe72e2-2c24-4cbd-9441-a681fcf507e4"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/ashutosh/Desktop/ugmqa_project/dm_transformer (3).ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#ajit\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate5_spectral2.csv')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# dm\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm_4featu.csv')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/mfcc_simple_mean_newdm_2075.csv')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/spectral_centroid_meandm_2075_200.csv')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ashutosh/Desktop/ugmqa_project/dm_transformer%20%283%29.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mUnnamed: 0\u001b[39m\u001b[39m'\u001b[39m], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/Desktop/ugmqa_project/venv/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm.csv'"
          ]
        }
      ],
      "source": [
        "#ajit\n",
        "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate5_spectral2.csv')\n",
        "# dm\n",
        "df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm.csv')\n",
        "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm_4featu.csv')\n",
        "\n",
        "\n",
        "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/melspectogram_mean_newdm_2075.csv')\n",
        "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/chroma_cqt_simple_mean_newdm_2075.csv')\n",
        "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/mfcc_simple_mean_newdm_2075.csv')\n",
        "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/spectral_centroid_meandm_2075_200.csv')\n",
        "\n",
        "df = df.drop(['Unnamed: 0'], axis = 1)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HrbtbLXcbTx",
        "outputId": "7a1af2ba-848e-44d8-d239-a2518c22f9bd"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "siz=415\n",
        "df_read = df.copy()\n",
        "df1 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df1.index)\n",
        "df2 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df2.index)\n",
        "df3 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df3.index)\n",
        "df4 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df4.index)\n",
        "df5 = df_read.copy()\n",
        "\n",
        "print(df1.shape)\n",
        "print(df2.shape)\n",
        "print(df3.shape)\n",
        "print(df4.shape)\n",
        "print(df5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j19bgqpcbWT",
        "outputId": "e4e9f119-b436-44fe-ab74-572cf6d7bca3"
      },
      "outputs": [],
      "source": [
        "q = list(df1.index)+list(df2.index)+list(df3.index)+list(df4.index)+list(df5.index)\n",
        "print(df1.index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT0Jrfa5cbZv",
        "outputId": "765d52d9-b8e2-4f6d-cd94-261bb7f7c39d"
      },
      "outputs": [],
      "source": [
        "#run call the transformer model\n",
        "#df_read = df.copy()\n",
        "#df_read=(df_read-df_read.mean())/df_read.std()\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train, test = train_test_split(df_read, test_size=0.2)\n",
        "\n",
        "train = pd.concat([df1,df2,df3,df4], axis=0)\n",
        "test = df5.copy()\n",
        "\n",
        "Y_train = np.array(train['class'])\n",
        "X_train= np.array(train.drop(['class'],axis=1))\n",
        "X_train=X_train.reshape(X_train.shape[0], 1 , X_train.shape[1])\n",
        "\n",
        "Y_val=np.array(test['class'])\n",
        "X_val = np.array(test.drop(['class'],axis=1))\n",
        "X_val=X_val.reshape(X_val.shape[0], 1 , X_val.shape[1])\n",
        "NUM_LAYERS =  4\n",
        "\n",
        "D_MODEL = X_train.shape[2]\n",
        "NUM_HEADS =  4\n",
        "UNITS =  2048\n",
        "DROPOUT = 0.1 #0.1\n",
        "TIME_STEPS= X_train.shape[1]\n",
        "OUTPUT_SIZE=1\n",
        "batch_size=64\n",
        "\n",
        "model = transformer(time_steps=TIME_STEPS,\n",
        "  num_layers=NUM_LAYERS,\n",
        "  units=UNITS,\n",
        "  d_model=D_MODEL,\n",
        "  num_heads=NUM_HEADS,\n",
        "  dropout=DROPOUT,\n",
        "  output_size=OUTPUT_SIZE,\n",
        "  projection='linear')\n",
        "\n",
        "#run\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(0.00005), loss='mae') #org\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.000003), loss='mse')\n",
        "# model.compile(optimizer=tf.keras.optimizers.SGD(0.01), loss='mae')\n",
        "#\n",
        "# callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=80, restore_best_weights=True)\n",
        "# history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val), callbacks=[callback])\n",
        "history = model.fit(X_train,Y_train, epochs=1000, validation_data=(X_val, Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxMyaAwpcqdf"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "import time\n",
        "st = time.time()\n",
        "p1 = np.array(model(X_val)).flatten()\n",
        "end = time.time()\n",
        "# print(end, st, len(p1))\n",
        "print((end-st)/len(p1))\n",
        "p2 = np.array(model(X_train)).flatten()\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Say3gnZgi331",
        "outputId": "8cb662ec-46e3-428c-a3dc-5f3adeb2ff3a"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "from scipy.stats import kendalltau\n",
        "print(np.corrcoef(p2, Y_train), stats.spearmanr(p2, Y_train), kendalltau(p2,Y_train).correlation)\n",
        "np.corrcoef(p1, Y_val)[1][0], stats.spearmanr(p1, Y_val).correlation, kendalltau(p1,Y_val).correlation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST5WiH4KoeOh",
        "outputId": "b995e4a2-4e2a-412c-9c59-0ee632503d82"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ksXNLzMScqg6",
        "outputId": "218ba87c-4fe6-43c8-bf76-19bc5d9ce9b8"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.savefig(\"audio_dm_3_featu_.jpg\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
